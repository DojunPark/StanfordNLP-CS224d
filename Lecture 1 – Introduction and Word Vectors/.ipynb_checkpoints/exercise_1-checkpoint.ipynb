{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) WordNet\n",
    "- Searching synonym sets using WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Dojun\n",
      "[nltk_data]     Park\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.g. synonym sets containing \"good\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: good.n.01, \n",
      "pos: noun, \n",
      "lemmatizations: good, \n",
      "------------------------------------------------\n",
      "name: good.n.02, \n",
      "pos: noun, \n",
      "lemmatizations: good, goodness, \n",
      "------------------------------------------------\n",
      "name: good.n.03, \n",
      "pos: noun, \n",
      "lemmatizations: good, goodness, \n",
      "------------------------------------------------\n",
      "name: commodity.n.01, \n",
      "pos: noun, \n",
      "lemmatizations: commodity, trade_good, good, \n",
      "------------------------------------------------\n",
      "name: good.a.01, \n",
      "pos: adj, \n",
      "lemmatizations: good, \n",
      "------------------------------------------------\n",
      "name: full.s.06, \n",
      "pos: adj (s), \n",
      "lemmatizations: full, good, \n",
      "------------------------------------------------\n",
      "name: good.a.03, \n",
      "pos: adj, \n",
      "lemmatizations: good, \n",
      "------------------------------------------------\n",
      "name: estimable.s.02, \n",
      "pos: adj (s), \n",
      "lemmatizations: estimable, good, honorable, respectable, \n",
      "------------------------------------------------\n",
      "name: beneficial.s.01, \n",
      "pos: adj (s), \n",
      "lemmatizations: beneficial, good, \n",
      "------------------------------------------------\n",
      "name: good.s.06, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, \n",
      "------------------------------------------------\n",
      "name: good.s.07, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, just, upright, \n",
      "------------------------------------------------\n",
      "name: adept.s.01, \n",
      "pos: adj (s), \n",
      "lemmatizations: adept, expert, good, practiced, proficient, skillful, skilful, \n",
      "------------------------------------------------\n",
      "name: good.s.09, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, \n",
      "------------------------------------------------\n",
      "name: dear.s.02, \n",
      "pos: adj (s), \n",
      "lemmatizations: dear, good, near, \n",
      "------------------------------------------------\n",
      "name: dependable.s.04, \n",
      "pos: adj (s), \n",
      "lemmatizations: dependable, good, safe, secure, \n",
      "------------------------------------------------\n",
      "name: good.s.12, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, right, ripe, \n",
      "------------------------------------------------\n",
      "name: good.s.13, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, well, \n",
      "------------------------------------------------\n",
      "name: effective.s.04, \n",
      "pos: adj (s), \n",
      "lemmatizations: effective, good, in_effect, in_force, \n",
      "------------------------------------------------\n",
      "name: good.s.15, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, \n",
      "------------------------------------------------\n",
      "name: good.s.16, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, serious, \n",
      "------------------------------------------------\n",
      "name: good.s.17, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, sound, \n",
      "------------------------------------------------\n",
      "name: good.s.18, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, salutary, \n",
      "------------------------------------------------\n",
      "name: good.s.19, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, honest, \n",
      "------------------------------------------------\n",
      "name: good.s.20, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, undecomposed, unspoiled, unspoilt, \n",
      "------------------------------------------------\n",
      "name: good.s.21, \n",
      "pos: adj (s), \n",
      "lemmatizations: good, \n",
      "------------------------------------------------\n",
      "name: well.r.01, \n",
      "pos: adv, \n",
      "lemmatizations: well, good, \n",
      "------------------------------------------------\n",
      "name: thoroughly.r.02, \n",
      "pos: adv, \n",
      "lemmatizations: thoroughly, soundly, good, \n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# make a dictionary\n",
    "poses = {'n':'noun', 'v':'verb', 's':'adj (s)', 'a':'adj', 'r':'adv'}\n",
    "\n",
    "# for loop\n",
    "for synset in wn.synsets('good'):\n",
    "    print('name: {}, \\npos: {}, \\nlemmatizations: {}, \\n{}'.format(synset.name(), \n",
    "                                                          poses[synset.pos()],\n",
    "                                                          ', '.join([l.name() for l in synset.lemmas()]),\n",
    "                                                          '------------------------------------------------'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.g. hypernyms of \"panda\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('procyonid.n.01'),\n",
       " Synset('carnivore.n.01'),\n",
       " Synset('placental.n.01'),\n",
       " Synset('mammal.n.01'),\n",
       " Synset('vertebrate.n.01'),\n",
       " Synset('chordate.n.01'),\n",
       " Synset('animal.n.01'),\n",
       " Synset('organism.n.01'),\n",
       " Synset('living_thing.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('object.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda = wn.synset('panda.n.01')\n",
    "hyper = lambda s: s.hypernyms()\n",
    "\n",
    "list(panda.closure(hyper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Problem with words as discrete symbols\n",
    "- even two different words are similar in meaning (these are synonym), two vectors of these words are orthogonal.\n",
    "- There is no natural notion of similarity for one-hot vectors.\n",
    "<br/><br/>\n",
    "Could try to rely on WordNet's list of synonyms to get similarity? <br/>\n",
    "But it is well-known to fail badly: incompleteness etc.\n",
    "<br/>\n",
    "\n",
    "#### Instead, learn to encode silmilarity in the vectors themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Representing words by their context\n",
    "- Distributional semantics: A word's meaning is given by the words that frequently appear close-by.\n",
    "- One of the most successful ideas of modern statistical NLP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors\n",
    "- word vectors are somtimes called word embeddings or word representations.\n",
    "- They are a distributed representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Word2Vec\n",
    ": Word2Vec is a framework for learning word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
